{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import text \n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def getTrainHoldoutSplit(df, dfLabel, holdoutSize=0.20):\n",
    "    from sklearn import model_selection \n",
    "    dfHoldOut = None\n",
    "    dfHoldOutLabel = None\n",
    "\n",
    "    cv_pre = model_selection.StratifiedShuffleSplit(n_splits=1, test_size=holdoutSize, random_state=1)\n",
    "    for train_index, test_index in cv_pre.split(df, dfLabel):\n",
    "        y_train, y_test = dfLabel[train_index], dfLabel[test_index]\n",
    "        x_train, x_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        df, dfLabel = x_train, y_train\n",
    "        dfHoldOut, dfHoldOutLabel = x_test, y_test\n",
    "\n",
    "    print(\"==================== Data Set ==================================\")\n",
    "    print(\"Holdout Set => \", dfHoldOut.shape)\n",
    "    print(\"Train Set => \", df.shape)\n",
    "    print(\"==================== Data Set ==================================\")\n",
    "    return df, dfLabel, dfHoldOut, dfHoldOutLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Data Set ==================================\n",
      "Holdout Set =>  (270732, 46)\n",
      "Train Set =>  (1534142, 46)\n",
      "==================== Data Set ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/series.py:842: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Data Set ==================================\n",
      "Holdout Set =>  (276146, 46)\n",
      "Train Set =>  (1257996, 46)\n",
      "==================== Data Set ==================================\n",
      "==========Train Sample Distribution =============\n",
      "0.0    985215\n",
      "1.0     84356\n",
      "Name: pred, dtype: int64\n",
      "==========Validation Sample Distribution ===========\n",
      "0.0    216204\n",
      "1.0     18296\n",
      "Name: pred, dtype: int64\n",
      "==========Holdout Sample Distribution ===========\n",
      "0    249082\n",
      "1     21650\n",
      "Name: pred, dtype: int64\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=10000)\n",
    "# dfTest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv', nrows=1000)\n",
    "df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "dfTest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n",
    "\n",
    "df['pred'] = df['target'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "# df = pd.read_csv(\"../input/fake-news-detection/data.csv\")\n",
    "# df = df.fillna('')\n",
    "# df['comment_text'] = df['Headline']\n",
    "# df['pred'] = df['Label']\n",
    "# df['id'] = df.index\n",
    "# dfTest = df\n",
    "\n",
    "def filter_initial_sentence(x):\n",
    "    return \" \".join([re.sub('[^a-z0-9 ]+', '', x) if re.sub('[^a-z0-9 ]+', '', x) else x for x in x.lower().split()])\n",
    "\n",
    "def tokenize_initial_sentence(x):\n",
    "    x = re.sub(\"[’‘'“\\\"”.\\n\\t\\r]+\", '', x.lower())\n",
    "    pat = re.compile(r\"([—!#$%&()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~\\t\\n…])\")\n",
    "    x = re.sub(\"[0-9]+\", '', x.lower())\n",
    "    return pat.sub(\" \\\\1 \", x)\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(tokenize_initial_sentence)\n",
    "dfTest['comment_text'] = dfTest['comment_text'].apply(tokenize_initial_sentence)\n",
    "\n",
    "df, dfLabel, dfHoldOut, dfHoldOutLabel = getTrainHoldoutSplit(df, df['pred'], holdoutSize=0.15)\n",
    "df, dfLabel, dfVal, dfValLabel = getTrainHoldoutSplit(df, df['pred'], holdoutSize=0.18)\n",
    "\n",
    "# Check Positive vs Negative samples\n",
    "print(\"==========Train Sample Distribution =============\")\n",
    "print(dfLabel.value_counts())\n",
    "print(\"==========Validation Sample Distribution ===========\")\n",
    "print(dfValLabel.value_counts())\n",
    "print(\"==========Holdout Sample Distribution ===========\")\n",
    "print(dfHoldOutLabel.value_counts())\n",
    "print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Keras used for tokenization and unique  word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713144\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "max_features = 2000000\n",
    "# tokenizer.fit_on_texts(df['comment_text'].tolist())\n",
    "tokenizer = text.Tokenizer(num_words = max_features, filters=\"\", lower=True, split=\" \")\n",
    "tokenizer.fit_on_texts(df['comment_text'].tolist() + dfHoldOut['comment_text'].tolist() + dfTest['comment_text'].tolist())\n",
    "\n",
    "print(len(tokenizer.word_index))\n",
    "tokenize_dict = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Loadup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../input/vector-jigsaw/jigsaw.pkl\n",
      "Loaded\n",
      "792179\n",
      "lookup_index: 713144\n",
      "Total Words: 713144 Total Unknow Words: 2132 Total Found: 711012\n",
      "Embeddings shape: (713145, 150)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "(713145, 150)\n",
      "['cannot', 'gonna', 'gotta', 'wanna', 'gimme', '\\xa0', 'lemme', '\\xa0the', '\\u2004\\u2004\\u2004usa', '\\u2009', '\\xa0and', '\\xa0million', '\\xa0a', '\\u2009\\u2009', '\\xa0http', '\\u200aand', '\\xa0if', '\\xa0that', '\\u2002', '\\u2028', 'of\\xa0the', '✨\\u2005\\u2005', 'repatriate»', 'for\\xa0the', '\\xa0\\xa0', 'tombeau»', '☭\\u2004', 'growth\\u2028', '\\xa0people', '«sir', '»«', '\\u2009trillion', '»i', '\\xa0of', '\\xa0\\xa0\\xa0\\xa0\\xa0', '\\xa0is', 'that\\xa0there', '»theres', '\\xa0billion', 'a\\xa0', '\\u2028\\u2028•', 'c\\u2009', 'president\\xa0john', '\\xa0its', '\\u2009°c', '«superhero', 'act\\xa0', '«it', 'all\\xa0', '\\xa0obama', '\\xa0i', 'of«', 'at\\xa0\\xa0per', '«rhetorical', '\\x85us', 'ontario«regulation', '\\u3000', 'all\\xa0the', '\\xa0in', 'greenbook\\xa0cuts', 'affairs\\xa0https', 'the\\xa0termination', 'fix\\xa0americas', 'system\\xa0in', 'the\\xa0bureau', 'the\\xa0', '§\\xa0', '\\xa0thats', 'of\\xa0', 'principle\\u2028go', '\\u2028used', 'peopleproblems\\xa0are', 'can\\xa0broker', 'east\\xa0and\\xa0revolutionize', 'by\\xa0', '\\xa0we', 'to\\xa0the', '\\xa0not', '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0there', '\\xa0including', '\\xa0this', 'vegas\\xa0although', '\\xa0percent', 'month\\u200a', '»you', '\\u2004', 'targets\\u2028•supporting', 'district\\u2028•virtual', 'kelly\\xa0', 'peter\\xa0micciche\\xa0', 'bishop\\xa0', 'mike\\xa0dunleavy\\xa0', 'giessel\\xa0', 'anna\\xa0', 'mackinnon\\xa0', 'than\\xa0', 'problems\\u3000read', 'trust\\xa0that', 'slimy\\xa0grasp', '\\xa0occasioned']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_embeddings_partial(embedings_filepath, tokenize_dict, embedding_size=300):\n",
    "    def load_embeddings_vec(path):\n",
    "        def nop(it, *a, **k):\n",
    "            return it\n",
    "\n",
    "        def get_coefs(word, *arr):\n",
    "            return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "        tqdm = nop\n",
    "        with open(path) as f:\n",
    "            return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n",
    "\n",
    "    def load_embeddings_pkl(path):\n",
    "        with open(path,'rb') as f:\n",
    "            emb_arr = pickle.load(f)\n",
    "        return emb_arr\n",
    "    print(\"Loading file\", embedings_filepath)\n",
    "    if embedings_filepath.endswith(\"pkl\"):\n",
    "        embedding_index_ = load_embeddings_pkl(embedings_filepath)\n",
    "    else:\n",
    "        embedding_index_ = load_embeddings_vec(embedings_filepath)\n",
    "    print(\"Loaded\")\n",
    "\n",
    "    embedding_index = {}\n",
    "    for key, value in embedding_index_.items():\n",
    "        embedding_index[key.lower()] = value\n",
    "    del embedding_index_\n",
    "\n",
    "    print(len(embedding_index))\n",
    "    embeddings = np.zeros((len(tokenize_dict) + 1, embedding_size))\n",
    "    unknown_words = []\n",
    "\n",
    "    tokens = list(tokenize_dict.keys())\n",
    "    found = 0\n",
    "    lookup_index = OrderedDict()\n",
    "    for i in range(len(tokens)):\n",
    "        try:\n",
    "            word = tokens[i]\n",
    "            lookup_index[word] = i\n",
    "            embeddings[i] = embedding_index[word]\n",
    "            found += 1\n",
    "        except Exception as err:\n",
    "            unknown_words.append(word)\n",
    "\n",
    "    del embedding_index\n",
    "    print(\"lookup_index:\", len(list(lookup_index.keys())))\n",
    "    \n",
    "    print(\"Total Words:\", len(tokenize_dict), \"Total Unknow Words:\", len(unknown_words), \"Total Found:\", found)\n",
    "    print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "    \"\"\" Dictionary which gives index of word in embeddings,\n",
    "    Eg. lookup_index['word'] will return integer value, and at that index location in embeddings we can find its vector \"\"\"\n",
    "    lookup_index_tf = tf.constant(list(lookup_index.keys()))\n",
    "    table = tf.contrib.lookup.index_table_from_tensor(mapping=lookup_index_tf, default_value=lookup_index[\"-\"])\n",
    "    gc.collect()\n",
    "    return embeddings, table, unknown_words\n",
    "\n",
    "embedding_filepath = \"../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl\"\n",
    "embedding_filepath = \"../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl\"\n",
    "embedding_filepath = \"../input/vector-jigsaw/jigsaw.pkl\"\n",
    "# embedding_filepath = \"../input/crawl300d2m/crawl-300d-2M.vec\"\n",
    "# embedding_filepath = \"../input/glove-840b-300d/glove.840B.300d.txt\"\n",
    "\n",
    "embeddings, table, unknown_words = load_embeddings_partial(embedding_filepath, tokenize_dict,\n",
    "                                                           embedding_size=150)\n",
    "embeddings_tf = tf.placeholder(tf.float32, embeddings.shape, name='embeddings_tf')\n",
    "\n",
    "print(embeddings.shape)\n",
    "print(unknown_words[0:100])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x  = 150\n",
    "n_y = 2\n",
    "n_t = 200\n",
    "result_at_mod = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7fb7616bd128>\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "x: (?, 200, 150)\n",
      "(?, 200, 150)\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f920f18958>:23: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling1d instead.\n",
      "CONV1 (?, 100, 64)\n",
      "CONV2 (?, 50, 128)\n",
      "CONV3 (?, 25, 256)\n",
      "CONV4 (?, 13, 512)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "FLATTEN (?, 6656)\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f920f18958>:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f920f18958>:49: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Dense1 (?, 1024)\n",
      "Dense2 (?, 512)\n",
      "logits: Tensor(\"dense_1/LeakyRelu:0\", shape=(?, 2), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f920f18958>:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7fb7616bd128>\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "results = {}\n",
    "G = tf.Graph()\n",
    "print(G)\n",
    "with G.as_default():\n",
    "    counter = tf.Variable(0, name='counter', trainable=False)\n",
    "    assert counter.graph is G\n",
    "\n",
    "    xav_init = tf.contrib.layers.xavier_initializer\n",
    "    keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "    learning_rate = tf.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "    x = tf.placeholder(shape=[None, n_t, n_x], dtype=tf.float32, name='x')\n",
    "    y = tf.placeholder(shape=[None], dtype=tf.int32, name='y')\n",
    "    class_weights = tf.placeholder(shape=[1, 2], dtype=tf.float32)\n",
    "    print(\"x:\", x.shape)\n",
    "    yt = tf.reshape(y, [-1])  # check this print yt and yb\n",
    "    \n",
    "    input_ = tf.cast(x, tf.float32)\n",
    "    print(input_.shape)\n",
    "    with tf.variable_scope(\"conv1\") as scope:\n",
    "        net = tf.contrib.layers.conv1d(input_, 64, 5, activation_fn=tf.nn.leaky_relu, padding='SAME',\n",
    "            weights_initializer=xav_init(),scope=scope,reuse=False)\n",
    "        net = tf.layers.max_pooling1d(net, pool_size=3, strides=2, padding='SAME')\n",
    "        print(\"CONV1\", net.shape)\n",
    "\n",
    "    with tf.variable_scope(\"conv2\") as scope:\n",
    "        net = tf.contrib.layers.conv1d(net, 128, 5, activation_fn=tf.nn.leaky_relu, padding='SAME',\n",
    "            weights_initializer=xav_init(), scope=scope,reuse=False)\n",
    "        net = tf.layers.max_pooling1d(net, pool_size=3, strides=2, padding='SAME')\n",
    "        print(\"CONV2\", net.shape)\n",
    "\n",
    "    with tf.variable_scope(\"conv3\") as scope:\n",
    "        net = tf.contrib.layers.conv1d(net, 256, 5, activation_fn=tf.nn.leaky_relu, padding='SAME',\n",
    "            weights_initializer=xav_init(), scope=scope,reuse=False)\n",
    "        net = tf.layers.max_pooling1d(net, pool_size=3, strides=2, padding='SAME')\n",
    "        print(\"CONV3\", net.shape)\n",
    "\n",
    "    with tf.variable_scope(\"conv4\") as scope:\n",
    "        net = tf.contrib.layers.conv1d(net, 512, 5, activation_fn=tf.nn.leaky_relu, padding='SAME',\n",
    "            weights_initializer=xav_init(), scope=scope,reuse=False)\n",
    "        net = tf.layers.max_pooling1d(net, pool_size=3, strides=2, padding='SAME')\n",
    "        print(\"CONV4\", net.shape)\n",
    "    flatten = tf.contrib.layers.flatten(net)\n",
    "    print(\"FLATTEN\", flatten.shape)\n",
    "\n",
    "    with tf.variable_scope(\"dnn1\") as scope:\n",
    "        dense = tf.layers.dense(inputs=flatten, units=1024, kernel_initializer=xav_init(),\n",
    "                                activation=tf.nn.leaky_relu)\n",
    "        dense = tf.nn.dropout(dense, keep_prob=keep_prob)\n",
    "        print(\"Dense1\", dense.shape)\n",
    "\n",
    "    with tf.variable_scope(\"dnn2\") as scope:\n",
    "        dense = tf.layers.dense(inputs=dense, units=512, kernel_initializer=xav_init(), \n",
    "                            activation=tf.nn.leaky_relu)\n",
    "        print(\"Dense2\", dense.shape)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dense,kernel_initializer=xav_init(), \n",
    "                             activation=tf.nn.leaky_relu, units=2)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dense,kernel_initializer=xav_init(), \n",
    "                             activation=tf.nn.leaky_relu, units=2)\n",
    "\n",
    "    print(\"logits:\", logits)\n",
    "\n",
    "    predictions_softmax = tf.nn.softmax(logits)\n",
    "    predictions_argmax  =  tf.argmax(predictions_softmax, axis=1)\n",
    "\n",
    "    train_vars   = tf.trainable_variables() \n",
    "    l2_loss = tf.add_n([ tf.nn.l2_loss(v) for v in train_vars if 'bias' not in v.name ]) * 0.001\n",
    "    l2_loss_mean = tf.reduce_mean(l2_loss)\n",
    "\n",
    "    \n",
    "    yt_onehot = tf.one_hot(yt, n_y)\n",
    "    \n",
    "    weight_per_label = tf.linalg.matmul(tf.to_float(yt_onehot), tf.transpose(class_weights)) # shape [batch_size, 2]\n",
    "    loss_all = tf.math.multiply(weight_per_label, tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=yt))\n",
    "\n",
    "    loss_all_mean = tf.reduce_mean(loss_all)\n",
    "\n",
    "    #     loss_train = loss_all + 0.5 * (1 - f1)    \n",
    "    loss_train = loss_all + l2_loss_mean * 0.005\n",
    "    loss = tf.reduce_mean(loss_train)\n",
    "\n",
    "    tf.summary.scalar('loss_modified', loss)\n",
    "    tf.summary.scalar('loss', tf.reduce_mean(loss_all))\n",
    "\n",
    "    #     optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    #     tvars = tf.trainable_variables()\n",
    "    #     grads, _ = tf.clip_by_global_norm(tf.gradients(loss_all, tvars), 10)\n",
    "    #     train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_train)\n",
    "    global_step = tf.assign_add(counter, 1, name='global_step')\n",
    "\n",
    "    cls_sess = tf.Session()\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    cls_sess.run(init_op)\n",
    "\n",
    "    #     total_parameters = np.sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
    "    #     print(total_parameters)\n",
    "    print(loss.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iterations: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Train Progress 0 Loss(avg): 0.77 P: 0.12 R: 0.02 F1: 0.04 Acc: 0.92 Time: 0.1/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "\u001b[2K #### Train Progress 99 Loss(avg): 0.04 P: 0.69 R: 0.35 F1: 0.47 Acc: 0.94 Time: 2.85"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365.1125023365021\n",
      "Iterations: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Validation Eval Progress  99 Loss(avg): 0.03 P: 0.75 R: 0.45 F1: 0.56 Acc: 0.94 Time: 0.65"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.19712495803833\n",
      "Epoch: 1\n",
      "Iterations: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Train Progress 99 Loss(avg): 0.03 P: 0.75 R: 0.48 F1: 0.58 Acc: 0.95 Time: 2.88"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365.93937373161316\n",
      "Iterations: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Validation Eval Progress  99 Loss(avg): 0.02 P: 0.76 R: 0.47 F1: 0.58 Acc: 0.95 Time: 0.68"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.91509890556335\n",
      "Epoch: 2\n",
      "Iterations: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Train Progress 99 Loss(avg): 0.02 P: 0.76 R: 0.5 F1: 0.6 Acc: 0.95 Time: 2.8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371.54562044143677\n",
      "Iterations: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Validation Eval Progress  99 Loss(avg): 0.02 P: 0.76 R: 0.49 F1: 0.6 Acc: 0.95 Time: 0.63"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.91597962379456\n",
      "Epoch: 3\n",
      "Iterations: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Train Progress 99 Loss(avg): 0.02 P: 0.76 R: 0.51 F1: 0.61 Acc: 0.95 Time: 2.82"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373.8277699947357\n",
      "Iterations: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Validation Eval Progress  99 Loss(avg): 0.02 P: 0.73 R: 0.54 F1: 0.62 Acc: 0.95 Time: 0.66"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.62767291069031\n",
      "Epoch: 4\n",
      "Iterations: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Train Progress 99 Loss(avg): 0.02 P: 0.76 R: 0.52 F1: 0.62 Acc: 0.95 Time: 2.8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376.676584482193\n",
      "Iterations: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Validation Eval Progress  99 Loss(avg): 0.02 P: 0.74 R: 0.53 F1: 0.62 Acc: 0.95 Time: 0.68"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.51248669624329\n",
      "Epoch: 5\n",
      "Iterations: 1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Train Progress 99 Loss(avg): 0.02 P: 0.76 R: 0.52 F1: 0.62 Acc: 0.95 Time: 2.8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393.13282227516174\n",
      "Iterations: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Validation Eval Progress  99 Loss(avg): 0.02 P: 0.73 R: 0.54 F1: 0.62 Acc: 0.95 Time: 0.67"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.4983696937561\n",
      "Iterations: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2K #### Holdout Eval Progress  99 Loss(avg): 0.02 P: 0.73 R: 0.54 F1: 0.62 Acc: 0.95 Time: 0.64"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.83920550346375\n"
     ]
    }
   ],
   "source": [
    "def parse_function(row):\n",
    "        row = table.lookup(row)\n",
    "        output = tf.nn.embedding_lookup(embeddings_tf, row)\n",
    "        \"\"\" See how can we add below features that were their in the original\n",
    "        pos_tag(sent)\n",
    "        getWordFeatures(token)\n",
    "        \"\"\"\n",
    "        return output\n",
    "    \n",
    "def getDatasetIterator(ids, texts, labels, mode=\"TRAIN\", batchsize=2, dimentions=100):\n",
    "    def truncate(x):\n",
    "        dim = tf.size(x)\n",
    "        return tf.cond(tf.equal(dim, n_t), \n",
    "            lambda: x, lambda: tf.cond(tf.greater(dim, n_t),\n",
    "            lambda: tf.slice(x, [0], [n_t]), \n",
    "            lambda: x, 0))\n",
    "\n",
    "    sentences = tf.data.Dataset.from_tensor_slices(texts)\n",
    "    sentences = sentences.map(lambda string: tf.string_split([string]).values)\n",
    "    sentences = sentences.map(truncate)\n",
    "    #sentences = sentences.map(parse_function, num_parallel_calls=4)\n",
    "    sentences_embed = sentences.map(parse_function)\n",
    "    if mode in ['TRAIN', 'EVAL']:\n",
    "        ids =  tf.data.Dataset.from_tensor_slices(ids)\n",
    "        labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "        dataset = tf.data.Dataset.zip((ids, sentences_embed, labels))\n",
    "        if mode == \"TRAIN\":\n",
    "            dataset = dataset.shuffle(buffer_size=batchsize*2)\n",
    "        dataset = dataset.padded_batch(batchsize, padded_shapes=([], [n_t, dimentions], []),\n",
    "                                       drop_remainder=True)\n",
    "    elif mode in ['PREDICT']:\n",
    "        ids =  tf.data.Dataset.from_tensor_slices(ids)\n",
    "        dataset = tf.data.Dataset.zip((ids, sentences_embed))        \n",
    "        dataset = dataset.padded_batch(batchsize, padded_shapes=([], [n_t, dimentions]))\n",
    "    dataset = dataset.prefetch(1)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    init_op = iterator.initializer\n",
    "    return init_op, next_element\n",
    "\n",
    "def execute(df, batchsize=4, mode=\"TRAIN\", max_timestamps=200, comment=\"\"):\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: x.replace(\"\\n\", ''))\n",
    "\n",
    "    init_op_model, next_element_model = getDatasetIterator(df['id'], df['comment_text'], df['pred'] if mode in ['TRAIN', 'EVAL'] else None, \n",
    "                                                           mode=mode, batchsize=batchsize, dimentions=n_x)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    print(\"Iterations:\", int(math.ceil(df.shape[0] / batchsize)))\n",
    "    sess.run(init_op_model, feed_dict={embeddings_tf: embeddings})\n",
    "\n",
    "    eval_loss = []\n",
    "    train_loss = []\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    predictions = []\n",
    "\n",
    "    while True:\n",
    "        st = time.time()\n",
    "        try:\n",
    "            batch = sess.run(next_element_model)\n",
    "            ids = batch[0]\n",
    "            xb = batch[1]\n",
    "            if mode in ['TRAIN', 'EVAL']:\n",
    "                yb = batch[2].astype(np.int)\n",
    "\n",
    "            if xb.shape[1] > max_timestamps:\n",
    "                xb = xb[:, 0:max_timestamps, :]\n",
    "\n",
    "            if mode == \"TRAIN\":\n",
    "                ratio = (np.sum(yb) + 0.0001) / np.size(yb) \n",
    "                result = cls_sess.run([train_op, global_step, loss, predictions_argmax, yt],\n",
    "                                       feed_dict = {\n",
    "                                                x: xb, y: yb, keep_prob: 0.85, learning_rate: 0.002,\n",
    "                                                class_weights: [[ratio, 1.0 - ratio]],\n",
    "                                        })\n",
    "                global_step_, loss_, y_pred, y_true = result[1:5]\n",
    "                train_loss.append(loss_)\n",
    "                y_true_all.extend(y_true)\n",
    "                y_pred_all.extend(y_pred)\n",
    "                total_elem = df.shape[0]\n",
    "                total_processed = len(y_pred_all)\n",
    "                complete_percent = int((total_processed / total_elem) * 100 )\n",
    "\n",
    "                if complete_percent < 3 or complete_percent > 98 or complete_percent % result_at_mod == 0 :\n",
    "                    cmd = [\"####\", comment, \"Progress\", str(complete_percent), \n",
    "                           \"Loss(avg):\", str(round(np.mean(train_loss), 2)), \n",
    "                           \"P:\", str(round(metrics.precision_score(y_true_all, y_pred_all), 2)),\n",
    "                           \"R:\", str(round(metrics.recall_score(y_true_all, y_pred_all), 2)),\n",
    "                           \"F1:\", str(round(metrics.f1_score(y_true_all, y_pred_all), 2)),\n",
    "                           \"Acc:\", str(round(metrics.accuracy_score(y_true_all, y_pred_all), 2)),\n",
    "                           'Time:', str(round(time.time() - st, 2))]\n",
    "                    cmd = \" \".join(cmd)\n",
    "                    sys.stderr.write('\\r\\033[2K %s' % (cmd))\n",
    "                    sys.stderr.flush()\n",
    "\n",
    "                results[global_step_] = {\n",
    "                                        'P': round(metrics.precision_score(y_true, y_pred), 2),\n",
    "                                        'R': round(metrics.recall_score(y_true, y_pred), 2),\n",
    "                                        'F1': round(metrics.f1_score(y_true, y_pred), 2),\n",
    "                                        'ACC': round(metrics.accuracy_score(y_true, y_pred), 2),\n",
    "                                        'Loss': round(loss_, 3)\n",
    "                }\n",
    "\n",
    "            elif mode == \"EVAL\":\n",
    "                ratio = (np.sum(yb) + 0.0001) / np.size(yb) \n",
    "                result = cls_sess.run([loss, predictions_argmax, yt],\n",
    "                                       feed_dict = { \n",
    "                                                x: xb, y: yb, keep_prob: 1.0,\n",
    "                                                class_weights: [[ratio, 1.0 - ratio]]\n",
    "                                       })\n",
    "\n",
    "                loss_, y_pred, y_true = result[0: 3]\n",
    "#                     print(y_true, y_pred)\n",
    "#                     print(result[-2])\n",
    "                eval_loss.append(loss_)\n",
    "                y_true_all.extend(y_true)\n",
    "                y_pred_all.extend(y_pred)\n",
    "\n",
    "                total_elem = df.shape[0]\n",
    "                total_processed = len(y_pred_all)\n",
    "                complete_percent = int((total_processed / total_elem) * 100 )\n",
    "                if complete_percent < 3 or complete_percent > 98 or complete_percent % result_at_mod == 0 :\n",
    "                    cmd = [\"####\", comment, \"Progress \", str(complete_percent), \"Loss(avg):\", str(round(np.mean(eval_loss), 2)), \n",
    "                           \"P:\", str(round(metrics.precision_score(y_true_all, y_pred_all), 2)),\n",
    "                          \"R:\", str(round(metrics.recall_score(y_true_all, y_pred_all), 2)),\n",
    "                          \"F1:\", str(round(metrics.f1_score(y_true_all, y_pred_all), 2)),\n",
    "                          \"Acc:\", str(round(metrics.accuracy_score(y_true_all, y_pred_all), 2)),\n",
    "                          'Time:', str(round(time.time() - st, 2))]\n",
    "                    cmd = \" \".join(cmd)\n",
    "                    sys.stderr.write('\\r\\033[2K %s' % (cmd))\n",
    "                    sys.stderr.flush()\n",
    "            elif mode == \"PREDICT\":\n",
    "                result = cls_sess.run([predictions_softmax], feed_dict = { x: xb, keep_prob: 1.0 })\n",
    "                prediction = result[0]\n",
    "                prediction = list(zip(ids, prediction[:, 1]))\n",
    "                predictions.extend(prediction)\n",
    "            \n",
    "            del xb\n",
    "            del ids\n",
    "            \n",
    "        except tf.errors.OutOfRangeError as err:\n",
    "            break\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "    gc.collect()\n",
    "#     time.sleep(5)\n",
    "    return predictions\n",
    "\n",
    "# df = shuffle(df.head(1))\n",
    "# print(df[['comment_text', 'pred']].head(1))\n",
    "\n",
    "# execute(df.head(2048), batchsize=1024, totalEpoch=3, mode=\"TRAIN\", comment=\"Train\")\n",
    "\n",
    "# epoch = 4\n",
    "epoch = 6\n",
    "for i in range(epoch):\n",
    "    print(\"Epoch:\", i)\n",
    "    st = time.time()\n",
    "    execute(df, batchsize=1024, mode=\"TRAIN\", max_timestamps=n_t, comment=\"Train\")\n",
    "    print(time.time() - st)\n",
    "    st = time.time()\n",
    "    execute(dfVal, batchsize=1024, mode=\"EVAL\", max_timestamps=n_t, comment=\"Validation Eval\")\n",
    "    print(time.time() - st)\n",
    "\n",
    "st = time.time()\n",
    "execute(dfHoldOut, batchsize=1024, mode=\"EVAL\", max_timestamps=n_t, comment=\"Holdout Eval\")\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97320, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = execute(dfTest, batchsize=1024, max_timestamps=n_t, mode=\"PREDICT\", comment=\"Predictions\")\n",
    "dfResult = pd.DataFrame(predictions, columns=['id', 'prediction'])\n",
    "dfResult.to_csv(\"submission.csv\", index=False)\n",
    "dfResult.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "window = 5\n",
    "iterations = sorted(results.keys())\n",
    "f1 = pd.Series([results[x]['F1'] for x in iterations]).rolling(window=window).mean()\n",
    "p = pd.Series([results[x]['P'] for x in iterations]).rolling(window=window).mean()\n",
    "r = pd.Series([results[x]['R'] for x in iterations]).rolling(window=window).mean()\n",
    "acc = pd.Series([results[x]['ACC'] for x in iterations]).rolling(window=window).mean()\n",
    "loss_vals = pd.Series([results[x]['Loss'] for x in iterations]).rolling(window=window).mean()\n",
    "\n",
    "# plt.plot(year, pop_pakistan, color='g')\n",
    "rows = 3\n",
    "cols = 2\n",
    "\n",
    "plt.subplot(rows, cols, 1)\n",
    "plt.plot(iterations, f1, color='orange')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('F1')\n",
    "\n",
    "plt.subplot(rows, cols, 2)\n",
    "plt.plot(iterations, p, color='blue')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.subplot(rows, cols, 3)\n",
    "plt.plot(iterations, r, color='black')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "plt.subplot(rows, cols, 4)\n",
    "plt.plot(iterations, acc, color='green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Acc')\n",
    "\n",
    "plt.subplot(rows, cols, 5)\n",
    "plt.plot(iterations, loss_vals, color='red')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
